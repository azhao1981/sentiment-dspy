{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset\n",
    "\n",
    "https://dspy-docs.vercel.app/docs/building-blocks/data\n",
    "\n",
    "https://dspy-docs.vercel.app/docs/cheatsheet#dspy-dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['感激', '好的,那我谢谢您了。', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"../.data/mix_model/data/all_raretrible.txt\"\n",
    "file_path = \"/home/azhao/projects/ai/train/liubin/mix_model/data/all_raretrible.txt\"\n",
    "data = open(file_path, \"r\").read().split(\"\\n\")\n",
    "data = [x.strip().split(\",\") for x in data if len(x) > 0]\n",
    "data = [[x[0], \",\".join(x[1:]), \"\", \"\", \"\"] for x in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 转换 data 到 pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"text\", \"pred_label\", \"score\", \"keywords\"])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "cvs_file = \"../.data/data.csv\"\n",
    "df.to_csv(cvs_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd3bb3ac7eb46fe9d9a43f1b6d672d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'label': '感激', 'text': '好的,那我谢谢您了。', 'score': None, 'pred_label': None, 'keywords': None}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets import DataLoader\n",
    "\n",
    "# 创建 dspy.datasets 对象\n",
    "dl = DataLoader()\n",
    "# fields 选择指定列 input_keys\n",
    "dataset = dl.from_csv(\n",
    "    cvs_file,\n",
    "    fields=(\"label\", \"text\", \"score\", \"pred_label\", \"score\", \"keywords\"),\n",
    "    input_keys=(\"text\",),\n",
    ")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感激\n",
      "好的,那我谢谢您了。\n",
      "Example({'label': '感激', 'score': None, 'pred_label': None, 'keywords': None}) (input_keys=None)\n",
      "Example({'text': '好的,那我谢谢您了。'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].get(\"label\"))\n",
    "print(dataset[0].get(\"text\"))\n",
    "print(dataset[0].labels())\n",
    "print(dataset[0].inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改用 stratified_sample 来取得 平均分布的数据集\n",
    "splits = dl.train_test_split(dataset, train_size=20, test_size=50)\n",
    "# splits = dl.train_test_split(dataset, train_size=20, test_size=50, stratify=dataset['label'])\n",
    "\n",
    "train_dataset = splits[\"train\"]\n",
    "test_dataset = splits[\"test\"]\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'中性': 7, '惊讶': 5, '感激': 4, '生气': 3, '抱怨': 1})\n",
      "Counter({'中性': 17, '感激': 10, '生气': 8, '惊讶': 6, '焦急': 3, '高兴': 3, '抱怨': 3})\n"
     ]
    }
   ],
   "source": [
    "# 统计 label 分布, 其实我们希望 label 分布是均匀的，并随机分布\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(item.get(\"label\") for item in train_dataset)\n",
    "print(label_counts)\n",
    "\n",
    "label_counts = Counter(item.get(\"label\") for item in test_dataset)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_example = dl.sample(dataset, n=20)  # `dataset` is a List of dspy.Example\n",
    "print(len(sampled_example), sampled_example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "def stratified_sample(dataset, label_attr, *dataset_sizes):\n",
    "    label_groups = defaultdict(list)\n",
    "    for item in dataset:\n",
    "        label = getattr(item, label_attr)\n",
    "        label_groups[label].append(item)\n",
    "\n",
    "    result_sets = [[] for _ in dataset_sizes]\n",
    "\n",
    "    for label, items in label_groups.items():\n",
    "        random.shuffle(items)\n",
    "        label_sizes = [size // len(label_groups) for size in dataset_sizes]\n",
    "        start = 0\n",
    "        for i, size in enumerate(label_sizes):\n",
    "            end = start + size\n",
    "            result_sets[i].extend(items[start:end])\n",
    "            start = end\n",
    "\n",
    "    all_items = [item for items in label_groups.values() for item in items]\n",
    "    for i, (result_set, target_size) in enumerate(zip(result_sets, dataset_sizes)):\n",
    "        shortage = target_size - len(result_set)\n",
    "        if shortage > 0:\n",
    "            result_sets[i].extend(random.sample(all_items, shortage))\n",
    "\n",
    "    return result_sets\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "train_set, test_set, sample_set = stratified_sample(dataset, \"label\", 20, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'感激': 5, '中性': 4, '生气': 3, '焦急': 2, '惊讶': 2, '高兴': 2, '抱怨': 2})\n",
      "Counter({'高兴': 8, '感激': 7, '中性': 7, '焦急': 7, '惊讶': 7, '抱怨': 7, '生气': 7})\n",
      "Counter({'感激': 3, '惊讶': 2, '中性': 1, '焦急': 1, '高兴': 1, '抱怨': 1, '生气': 1})\n"
     ]
    }
   ],
   "source": [
    "# 统计 label 分布, 其实我们希望 label 分布是均匀的，并随机分布\n",
    "from collections import Counter\n",
    "\n",
    "for dataset in [train_set, test_set, sample_set]:\n",
    "    label_counts = Counter(item.get(\"label\") for item in dataset)\n",
    "    print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱怨 交诚意金了为什么都不回信息?\n",
      "感激 麻烦你了谢谢[emoji053]\n",
      "生气 你们这什么玩意,这售后问题解决的太**了\n",
      "中性 其他没有了,我先在线提交材料试着解锁看看,谢谢。\n",
      "感激 哦哦好的感谢\n",
      "高兴 好,好,很好\n",
      "感激 算了,放弃,谢谢你\n",
      "生气 一块钱也坑\n",
      "感激 没有啦、非常感谢\n",
      "高兴 是啊哈哈哈\n",
      "感激 哦哦,好吧,谢谢你哦\n",
      "感激 拜拜,辛苦了,祝你新年好\n",
      "中性 一直在冲我刚刚一看就没电了\n",
      "惊讶 这个是最后一个退货?\n",
      "感激 对的是这个,谢谢啦!\n",
      "中性 可以延期是吧,好的\n",
      "中性 那东西是一样的么?\n",
      "惊讶 明明我插进去了\n",
      "中性 那么麻烦,那算了,\n",
      "中性 这个我下载不了,麻烦也一并发我邮箱,谢谢\n"
     ]
    }
   ],
   "source": [
    "for ex in train_dataset:\n",
    "    print(ex.get(\"label\"), ex.get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dspy\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "api_key = os.getenv(\"ONEAPI_API_KEY\")\n",
    "base_url = os.getenv(\"ONEAPI_BASE_URL\")\n",
    "\n",
    "# 测试要加 model_type ，不然因 model 不存在，会默认 text\n",
    "turbo = dspy.OpenAI(\n",
    "    api_key=api_key,\n",
    "    model=\"glm-4-flash\",\n",
    "    api_base=base_url,\n",
    "    model_type=\"chat\",\n",
    "    max_tokens=8000,\n",
    ")\n",
    "\n",
    "dspy.settings.configure(\n",
    "    lm=turbo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dsp import passages2text\n",
    "\n",
    "\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"sentiment analysis from text\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"list of input text\", format=passages2text)\n",
    "    answer = dspy.OutputField(\n",
    "        desc=\"question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\",\n",
    "        type=list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "samples = [x.text for x in sample_set]\n",
    "# Call the predictor on a particular input.\n",
    "pred = generate_answer(question=samples)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {samples}\")\n",
    "print(f\"Predicted Answer:\\n{pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n",
      "Question: Example({'label': '感激', 'text': '好的。知道了。谢谢您', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '没有,谢谢,再见', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '行。谢谢了', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '哦,我再试下,谢谢', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '太忙了,客服太少了吧', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '我这是无线流量怎样说欠费了', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '就是因为现在没办法归还,又不使用', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?', 'score': ' 0.8', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '我十四号回家老家过年了估计都还没有收到货', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '点错支付宝了。付不了款', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '太慢了,外面零下呢', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '可是客人着急啊', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '好的,请尽快邮寄。谢谢。', 'score': ' 0.9', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '已付款,请尽快处理,谢谢', 'score': ' 0.9', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '你赶紧结束', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '你们这个急人', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '可是你们回款太慢了', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '物流那么慢的吗?不是照片出关成功了吗?', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '早就还了,怎么扣那么多钱', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '什么鬼', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '我的账号怎么不在了', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '够硬气', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '这个还扣我费用啊', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '不交诚意金聊不了嘛不交诚意金聊不了嘛', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '湖南能用???这个', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '就是坑坑洼洼的,你可能看到??', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '比抢火车票还厉害', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '亲爱的,上午好!', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '哈哈哈好吧', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '哦,哈哈', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '抱怨', 'text': '你听的明白我说的话么', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '抱怨', 'text': '能看到我还在用跟你这么说', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "# 答案和问题对应起来\n",
    "def update_sample(sample_set, answer):\n",
    "    for sample, prediction in zip(sample_set, answer.split(\"\\n\")):\n",
    "        sample[\"score\"] = prediction.split(\",\")[1]\n",
    "        sample[\"pred_label\"] = prediction.split(\",\")[0].split(\" \")[-1]\n",
    "\n",
    "\n",
    "def sample_error_rate(sample_set):\n",
    "    incorrect_count = sum(\n",
    "        1 for sample in sample_set if sample[\"pred_label\"] != sample[\"label\"]\n",
    "    )\n",
    "    total_count = len(sample_set)\n",
    "    return incorrect_count / total_count\n",
    "\n",
    "\n",
    "update_sample(sample_set, pred.answer)\n",
    "print(sample_error_rate(sample_set))\n",
    "\n",
    "for sample in sample_set:\n",
    "    if sample[\"pred_label\"] != sample[\"label\"]:\n",
    "        print(f\"Question: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "sentiment analysis from text\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: list of input text\n",
      "Answer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "[1] «好的。知道了。谢谢您»\n",
      "[2] «非常感谢公司这么好的售后服务»\n",
      "[3] «谢谢你!不用了»\n",
      "[4] «哦哦,谢谢[emoji029]»\n",
      "[5] «嗯嗯,好的,太感谢了?»\n",
      "[6] «不用了!谢谢你啦»\n",
      "[7] «谢谢,我己经找到。麻烦你了亲»\n",
      "[8] «是这个,谢谢了»\n",
      "[9] «谢谢!没事儿。»\n",
      "[10] «没有,谢谢,再见»\n",
      "[11] «没有了。。非常感谢»\n",
      "[12] «行。谢谢了»\n",
      "[13] «嗯嗯,谢谢您»\n",
      "[14] «哦,我再试下,谢谢»\n",
      "[15] «之前我一直在同一机柜上扫码»\n",
      "[16] «太忙了,客服太少了吧»\n",
      "[17] «可是我的营业执照上有这个医疗器械的类目»\n",
      "[18] «说和商品同送的»\n",
      "[19] «我这是无线流量怎样说欠费了»\n",
      "[20] «您好,查询一下»\n",
      "[21] «你是真人还是电脑»\n",
      "[22] «我借充电宝才发现我的充电宝在菏泽»\n",
      "[23] «就是因为现在没办法归还,又不使用»\n",
      "[24] «虹桥火车站,国家会展中心附近»\n",
      "[25] «是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?»\n",
      "[26] «转债速度»\n",
      "[27] «我十四号回家老家过年了估计都还没有收到货»\n",
      "[28] «点错支付宝了。付不了款»\n",
      "[29] «太慢了,外面零下呢»\n",
      "[30] «可是客人着急啊»\n",
      "[31] «好的,请尽快邮寄。谢谢。»\n",
      "[32] «已付款,请尽快处理,谢谢»\n",
      "[33] «这个单子很紧急»\n",
      "[34] «你好我买的口红怎么还没发货呢?»\n",
      "[35] «你好,我的为什么那么久还没到嘞»\n",
      "[36] «麻烦您帮忙查一下,尽快安排发货,谢谢了»\n",
      "[37] «你赶紧结束»\n",
      "[38] «你们这个急人»\n",
      "[39] «可是你们回款太慢了»\n",
      "[40] «帮我催一催谢谢»\n",
      "[41] «我的期末成绩为什么还查不到»\n",
      "[42] «物流那么慢的吗?不是照片出关成功了吗?»\n",
      "[43] «吓死人啊»\n",
      "[44] «早就还了,怎么扣那么多钱»\n",
      "[45] «这是真的不回我了?»\n",
      "[46] «我看下都吓我一跳»\n",
      "[47] «什么鬼»\n",
      "[48] «我的账号怎么不在了»\n",
      "[49] «现在查的这么严了?»\n",
      "[50] «应该没事了吧,好吓人»\n",
      "[51] «够硬气»\n",
      "[52] «这个还扣我费用啊»\n",
      "[53] «不交诚意金聊不了嘛不交诚意金聊不了嘛»\n",
      "[54] «湖南能用???这个»\n",
      "[55] «就是坑坑洼洼的,你可能看到??»\n",
      "[56] «比抢火车票还厉害»\n",
      "[57] «亲爱的,上午好!»\n",
      "[58] «出来了哈哈哈哈»\n",
      "[59] «女子我喜欢你。»\n",
      "[60] «太期待了»\n",
      "[61] «好开心啊»\n",
      "[62] «很高兴与您的对话哦»\n",
      "[63] «[emoji033]哈哈»\n",
      "[64] «爱你爱你[emoji007]»\n",
      "[65] «哈哈哈[emoji030]»\n",
      "[66] «哈哈哈好吧»\n",
      "[67] «天猫还便宜好多!太棒了»\n",
      "[68] «[emoji047]真好»\n",
      "[69] «祝生日快乐!»\n",
      "[70] «哦,哈哈»\n",
      "[71] «就是看在小蜜红薯又小又细才买的,这次的那么大,还粗,蒸着吃不好吃唉»\n",
      "[72] «都两天了,还没更新完»\n",
      "[73] «就改个手机号,怎么这么难»\n",
      "[74] «进水很慢。»\n",
      "[75] «购买产品很难,开放时间好短»\n",
      "[76] «你听的明白我说的话么»\n",
      "[77] «能看到我还在用跟你这么说»\n",
      "[78] «丢到反馈都很久了»\n",
      "[79] «物流信息好慢呀»\n",
      "[80] «我认识的很多小伙伴都说因为太难»\n",
      "[81] «系统这两天为什么老掉线»\n",
      "[82] «要一个一个重新建,再重新关联,好繁琐哇»\n",
      "[83] «我自己用了就知道有问题啊»\n",
      "[84] «除了客服无人处理了?»\n",
      "[85] «客户快骂死我了。车商也骂»\n",
      "[86] «我他妈知道归还,但是没有还的地方你胖揍上哪还»\n",
      "[87] «为什么每次都是非要联系了客服才能到呢?不联系就死活不到?这是什么做法?»\n",
      "[88] «我当时就很生气»\n",
      "[89] «你们在哪里可以投诉呢!»\n",
      "[90] «你死全家»\n",
      "[91] «老板死了»\n",
      "[92] «你们这些狗»\n",
      "[93] «换你吗逼»\n",
      "[94] «良心不会痛吗?»\n",
      "[95] «骗钱也不是这样骗的吧»\n",
      "[96] «不然我还会向市场监管部门投诉»\n",
      "[97] «我炸你妈逼呀!»\n",
      "[98] «这不是骗钱呢»\n",
      "[99] «就是用的这个啊»\n",
      "[100] «已经好了,谢谢~»\n",
      "Answer:\u001b[32m [1] 中性, 0.5\n",
      "[2] 感激, 0.9\n",
      "[3] 感激, 0.8\n",
      "[4] 感激, 0.7\n",
      "[5] 感激, 0.8\n",
      "[6] 感激, 0.8\n",
      "[7] 感激, 0.9\n",
      "[8] 感激, 0.8\n",
      "[9] 感激, 0.8\n",
      "[10] 中性, 0.5\n",
      "[11] 感激, 0.9\n",
      "[12] 中性, 0.5\n",
      "[13] 感激, 0.8\n",
      "[14] 中性, 0.5\n",
      "[15] 中性, 0.5\n",
      "[16] 抱怨, 0.8\n",
      "[17] 中性, 0.5\n",
      "[18] 中性, 0.5\n",
      "[19] 抱怨, 0.7\n",
      "[20] 中性, 0.5\n",
      "[21] 中性, 0.5\n",
      "[22] 惊讶, 0.7\n",
      "[23] 抱怨, 0.8\n",
      "[24] 中性, 0.5\n",
      "[25] 感激, 0.8\n",
      "[26] 中性, 0.5\n",
      "[27] 抱怨, 0.7\n",
      "[28] 抱怨, 0.7\n",
      "[29] 抱怨, 0.8\n",
      "[30] 抱怨, 0.8\n",
      "[31] 感激, 0.8\n",
      "[32] 感激, 0.8\n",
      "[33] 焦急, 0.9\n",
      "[34] 焦急, 0.8\n",
      "[35] 焦急, 0.8\n",
      "[36] 焦急, 0.9\n",
      "[37] 生气, 0.8\n",
      "[38] 生气, 0.8\n",
      "[39] 抱怨, 0.8\n",
      "[40] 焦急, 0.8\n",
      "[41] 焦急, 0.8\n",
      "[42] 抱怨, 0.8\n",
      "[43] 惊讶, 0.9\n",
      "[44] 抱怨, 0.8\n",
      "[45] 惊讶, 0.8\n",
      "[46] 惊讶, 0.9\n",
      "[47] 生气, 0.8\n",
      "[48] 惊讶, 0.8\n",
      "[49] 惊讶, 0.8\n",
      "[50] 惊讶, 0.9\n",
      "[51] 生气, 0.8\n",
      "[52] 抱怨, 0.8\n",
      "[53] 抱怨, 0.8\n",
      "[54] 中性, 0.5\n",
      "[55] 抱怨, 0.8\n",
      "[56] 抱怨, 0.8\n",
      "[57] 中性, 0.5\n",
      "[58] 高兴, 0.9\n",
      "[59] 高兴, 0.9\n",
      "[60] 高兴, 0.9\n",
      "[61] 高兴, 0.9\n",
      "[62] 高兴, 0.9\n",
      "[63] 高兴, 0.9\n",
      "[64] 高兴, 0.9\n",
      "[65] 高兴, 0.9\n",
      "[66] 中性, 0.5\n",
      "[67] 高兴, 0.9\n",
      "[68] 高兴, 0.9\n",
      "[69] 高兴, 0.9\n",
      "[70] 中性, 0.5\n",
      "[71] 抱怨, 0.8\n",
      "[72] 抱怨, 0.8\n",
      "[73] 抱怨, 0.8\n",
      "[74] 抱怨, 0.8\n",
      "[75] 抱怨, 0.8\n",
      "[76] 中性, 0.5\n",
      "[77] 中性, 0.5\n",
      "[78] 抱怨, 0.8\n",
      "[79] 抱怨, 0.8\n",
      "[80] 抱怨, 0.8\n",
      "[81] 抱怨, 0.8\n",
      "[82] 抱怨, 0.8\n",
      "[83] 抱怨, 0.8\n",
      "[84] 抱怨, 0.8\n",
      "[85] 生气, 0.8\n",
      "[86] 生气, 0.8\n",
      "[87] 生气, 0.8\n",
      "[88] 生气, 0.8\n",
      "[89] 生气, 0.8\n",
      "[90] 生气, 0.8\n",
      "[91] 生气, 0.8\n",
      "[92] 生气, 0.8\n",
      "[93] 生气, 0.8\n",
      "[94] 生气, 0.8\n",
      "[95] 生气, 0.8\n",
      "[96] 生气, 0.8\n",
      "[97] 生气, 0.8\n",
      "[98] 生气, 0.8\n",
      "[99] 中性, 0.5\n",
      "[100] 感激, 0.9\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nsentiment analysis from text\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: list of input text\\nAnswer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\\n\\n---\\n\\nQuestion:\\n[1] «好的。知道了。谢谢您»\\n[2] «非常感谢公司这么好的售后服务»\\n[3] «谢谢你!不用了»\\n[4] «哦哦,谢谢[emoji029]»\\n[5] «嗯嗯,好的,太感谢了?»\\n[6] «不用了!谢谢你啦»\\n[7] «谢谢,我己经找到。麻烦你了亲»\\n[8] «是这个,谢谢了»\\n[9] «谢谢!没事儿。»\\n[10] «没有,谢谢,再见»\\n[11] «没有了。。非常感谢»\\n[12] «行。谢谢了»\\n[13] «嗯嗯,谢谢您»\\n[14] «哦,我再试下,谢谢»\\n[15] «之前我一直在同一机柜上扫码»\\n[16] «太忙了,客服太少了吧»\\n[17] «可是我的营业执照上有这个医疗器械的类目»\\n[18] «说和商品同送的»\\n[19] «我这是无线流量怎样说欠费了»\\n[20] «您好,查询一下»\\n[21] «你是真人还是电脑»\\n[22] «我借充电宝才发现我的充电宝在菏泽»\\n[23] «就是因为现在没办法归还,又不使用»\\n[24] «虹桥火车站,国家会展中心附近»\\n[25] «是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?»\\n[26] «转债速度»\\n[27] «我十四号回家老家过年了估计都还没有收到货»\\n[28] «点错支付宝了。付不了款»\\n[29] «太慢了,外面零下呢»\\n[30] «可是客人着急啊»\\n[31] «好的,请尽快邮寄。谢谢。»\\n[32] «已付款,请尽快处理,谢谢»\\n[33] «这个单子很紧急»\\n[34] «你好我买的口红怎么还没发货呢?»\\n[35] «你好,我的为什么那么久还没到嘞»\\n[36] «麻烦您帮忙查一下,尽快安排发货,谢谢了»\\n[37] «你赶紧结束»\\n[38] «你们这个急人»\\n[39] «可是你们回款太慢了»\\n[40] «帮我催一催谢谢»\\n[41] «我的期末成绩为什么还查不到»\\n[42] «物流那么慢的吗?不是照片出关成功了吗?»\\n[43] «吓死人啊»\\n[44] «早就还了,怎么扣那么多钱»\\n[45] «这是真的不回我了?»\\n[46] «我看下都吓我一跳»\\n[47] «什么鬼»\\n[48] «我的账号怎么不在了»\\n[49] «现在查的这么严了?»\\n[50] «应该没事了吧,好吓人»\\n[51] «够硬气»\\n[52] «这个还扣我费用啊»\\n[53] «不交诚意金聊不了嘛不交诚意金聊不了嘛»\\n[54] «湖南能用???这个»\\n[55] «就是坑坑洼洼的,你可能看到??»\\n[56] «比抢火车票还厉害»\\n[57] «亲爱的,上午好!»\\n[58] «出来了哈哈哈哈»\\n[59] «女子我喜欢你。»\\n[60] «太期待了»\\n[61] «好开心啊»\\n[62] «很高兴与您的对话哦»\\n[63] «[emoji033]哈哈»\\n[64] «爱你爱你[emoji007]»\\n[65] «哈哈哈[emoji030]»\\n[66] «哈哈哈好吧»\\n[67] «天猫还便宜好多!太棒了»\\n[68] «[emoji047]真好»\\n[69] «祝生日快乐!»\\n[70] «哦,哈哈»\\n[71] «就是看在小蜜红薯又小又细才买的,这次的那么大,还粗,蒸着吃不好吃唉»\\n[72] «都两天了,还没更新完»\\n[73] «就改个手机号,怎么这么难»\\n[74] «进水很慢。»\\n[75] «购买产品很难,开放时间好短»\\n[76] «你听的明白我说的话么»\\n[77] «能看到我还在用跟你这么说»\\n[78] «丢到反馈都很久了»\\n[79] «物流信息好慢呀»\\n[80] «我认识的很多小伙伴都说因为太难»\\n[81] «系统这两天为什么老掉线»\\n[82] «要一个一个重新建,再重新关联,好繁琐哇»\\n[83] «我自己用了就知道有问题啊»\\n[84] «除了客服无人处理了?»\\n[85] «客户快骂死我了。车商也骂»\\n[86] «我他妈知道归还,但是没有还的地方你胖揍上哪还»\\n[87] «为什么每次都是非要联系了客服才能到呢?不联系就死活不到?这是什么做法?»\\n[88] «我当时就很生气»\\n[89] «你们在哪里可以投诉呢!»\\n[90] «你死全家»\\n[91] «老板死了»\\n[92] «你们这些狗»\\n[93] «换你吗逼»\\n[94] «良心不会痛吗?»\\n[95] «骗钱也不是这样骗的吧»\\n[96] «不然我还会向市场监管部门投诉»\\n[97] «我炸你妈逼呀!»\\n[98] «这不是骗钱呢»\\n[99] «就是用的这个啊»\\n[100] «已经好了,谢谢~»\\nAnswer:\\x1b[32m [1] 中性, 0.5\\n[2] 感激, 0.9\\n[3] 感激, 0.8\\n[4] 感激, 0.7\\n[5] 感激, 0.8\\n[6] 感激, 0.8\\n[7] 感激, 0.9\\n[8] 感激, 0.8\\n[9] 感激, 0.8\\n[10] 中性, 0.5\\n[11] 感激, 0.9\\n[12] 中性, 0.5\\n[13] 感激, 0.8\\n[14] 中性, 0.5\\n[15] 中性, 0.5\\n[16] 抱怨, 0.8\\n[17] 中性, 0.5\\n[18] 中性, 0.5\\n[19] 抱怨, 0.7\\n[20] 中性, 0.5\\n[21] 中性, 0.5\\n[22] 惊讶, 0.7\\n[23] 抱怨, 0.8\\n[24] 中性, 0.5\\n[25] 感激, 0.8\\n[26] 中性, 0.5\\n[27] 抱怨, 0.7\\n[28] 抱怨, 0.7\\n[29] 抱怨, 0.8\\n[30] 抱怨, 0.8\\n[31] 感激, 0.8\\n[32] 感激, 0.8\\n[33] 焦急, 0.9\\n[34] 焦急, 0.8\\n[35] 焦急, 0.8\\n[36] 焦急, 0.9\\n[37] 生气, 0.8\\n[38] 生气, 0.8\\n[39] 抱怨, 0.8\\n[40] 焦急, 0.8\\n[41] 焦急, 0.8\\n[42] 抱怨, 0.8\\n[43] 惊讶, 0.9\\n[44] 抱怨, 0.8\\n[45] 惊讶, 0.8\\n[46] 惊讶, 0.9\\n[47] 生气, 0.8\\n[48] 惊讶, 0.8\\n[49] 惊讶, 0.8\\n[50] 惊讶, 0.9\\n[51] 生气, 0.8\\n[52] 抱怨, 0.8\\n[53] 抱怨, 0.8\\n[54] 中性, 0.5\\n[55] 抱怨, 0.8\\n[56] 抱怨, 0.8\\n[57] 中性, 0.5\\n[58] 高兴, 0.9\\n[59] 高兴, 0.9\\n[60] 高兴, 0.9\\n[61] 高兴, 0.9\\n[62] 高兴, 0.9\\n[63] 高兴, 0.9\\n[64] 高兴, 0.9\\n[65] 高兴, 0.9\\n[66] 中性, 0.5\\n[67] 高兴, 0.9\\n[68] 高兴, 0.9\\n[69] 高兴, 0.9\\n[70] 中性, 0.5\\n[71] 抱怨, 0.8\\n[72] 抱怨, 0.8\\n[73] 抱怨, 0.8\\n[74] 抱怨, 0.8\\n[75] 抱怨, 0.8\\n[76] 中性, 0.5\\n[77] 中性, 0.5\\n[78] 抱怨, 0.8\\n[79] 抱怨, 0.8\\n[80] 抱怨, 0.8\\n[81] 抱怨, 0.8\\n[82] 抱怨, 0.8\\n[83] 抱怨, 0.8\\n[84] 抱怨, 0.8\\n[85] 生气, 0.8\\n[86] 生气, 0.8\\n[87] 生气, 0.8\\n[88] 生气, 0.8\\n[89] 生气, 0.8\\n[90] 生气, 0.8\\n[91] 生气, 0.8\\n[92] 生气, 0.8\\n[93] 生气, 0.8\\n[94] 生气, 0.8\\n[95] 生气, 0.8\\n[96] 生气, 0.8\\n[97] 生气, 0.8\\n[98] 生气, 0.8\\n[99] 中性, 0.5\\n[100] 感激, 0.9\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: We will analyze each text individually based on the context and the tone of the language used, and then classify the sentiment accordingly. The sentiment classification includes ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']. We will also assign a score from 0 to 1.0 to represent the intensity of the sentiment.\n",
      "Predicted Answer: [1] 中性, 0.5\n",
      "[2] 感激, 0.9\n",
      "[3] 感激, 0.8\n",
      "[4] 感激, 0.7\n",
      "[5] 感激, 0.8\n",
      "[6] 感激, 0.8\n",
      "[7] 感激, 0.9\n",
      "[8] 感激, 0.9\n",
      "[9] 感激, 0.9\n",
      "[10] 中性, 0.5\n",
      "[11] 感激, 0.9\n",
      "[12] 中性, 0.5\n",
      "[13] 感激, 0.8\n",
      "[14] 中性, 0.5\n",
      "[15] 中性, 0.5\n",
      "[16] 抱怨, 0.8\n",
      "[17] 中性, 0.5\n",
      "[18] 中性, 0.5\n",
      "[19] 抱怨, 0.7\n",
      "[20] 中性, 0.5\n",
      "[21] 中性, 0.5\n",
      "[22] 中性, 0.5\n",
      "[23] 抱怨, 0.7\n",
      "[24] 中性, 0.5\n",
      "[25] 感激, 0.8\n",
      "[26] 中性, 0.5\n",
      "[27] 抱怨, 0.7\n",
      "[28] 抱怨, 0.7\n",
      "[29] 抱怨, 0.8\n",
      "[30] 抱怨, 0.8\n",
      "[31] 感激, 0.9\n",
      "[32] 感激, 0.9\n",
      "[33] 焦急, 0.9\n",
      "[34] 焦急, 0.8\n",
      "[35] 焦急, 0.8\n",
      "[36] 焦急, 0.9\n",
      "[37] 生气, 0.8\n",
      "[38] 生气, 0.8\n",
      "[39] 抱怨, 0.8\n",
      "[40] 焦急, 0.9\n",
      "[41] 焦急, 0.8\n",
      "[42] 抱怨, 0.7\n",
      "[43] 惊讶, 0.9\n",
      "[44] 抱怨, 0.8\n",
      "[45] 惊讶, 0.9\n",
      "[46] 惊讶, 0.9\n",
      "[47] 生气, 0.8\n",
      "[48] 生气, 0.8\n",
      "[49] 惊讶, 0.9\n",
      "[50] 惊讶, 0.9\n",
      "[51] 生气, 0.8\n",
      "[52] 抱怨, 0.7\n",
      "[53] 抱怨, 0.7\n",
      "[54] 中性, 0.5\n",
      "[55] 抱怨, 0.7\n",
      "[56] 抱怨, 0.7\n",
      "[57] 中性, 0.5\n",
      "[58] 高兴, 0.9\n",
      "[59] 高兴, 0.9\n",
      "[60] 高兴, 0.9\n",
      "[61] 高兴, 0.9\n",
      "[62] 高兴, 0.9\n",
      "[63] 高兴, 0.9\n",
      "[64] 高兴, 0.9\n",
      "[65] 高兴, 0.9\n",
      "[66] 中性, 0.5\n",
      "[67] 高兴, 0.9\n",
      "[68] 高兴, 0.9\n",
      "[69] 高兴, 0.9\n",
      "[70] 中性, 0.5\n",
      "[71] 抱怨, 0.7\n",
      "[72] 抱怨, 0.7\n",
      "[73] 抱怨, 0.7\n",
      "[74] 抱怨, 0.7\n",
      "[75] 抱怨, 0.7\n",
      "[76] 中性, 0.5\n",
      "[77] 中性, 0.5\n",
      "[78] 抱怨, 0.7\n",
      "[79] 抱怨, 0.7\n",
      "[80] 抱怨, 0.7\n",
      "[81] 抱怨, 0.7\n",
      "[82] 抱怨, 0.7\n",
      "[83] 抱怨, 0.7\n",
      "[84] 抱怨, 0.7\n",
      "[85] 生气, 0.8\n",
      "[86] 生气, 0.8\n",
      "[87] 生气, 0.8\n",
      "[88] 生气, 0.8\n",
      "[89] 生气, 0.8\n",
      "[90] 生气, 0.8\n",
      "[91] 生气, 0.8\n",
      "[92] 生气, 0.8\n",
      "[93] 生气, 0.8\n",
      "[94] 生气, 0.8\n",
      "[95] 生气, 0.8\n",
      "[96] 生气, 0.8\n",
      "[97] 生气, 0.8\n",
      "[98] 生气, 0.8\n",
      "[99] 中性, 0.5\n",
      "[100] 感激, 0.9\n"
     ]
    }
   ],
   "source": [
    "# 加上COT\n",
    "# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\n",
    "generate_answer_with_chain_of_thought = dspy.ChainOfThought(BasicQA)\n",
    "\n",
    "# Call the predictor on the same input.\n",
    "pred = generate_answer_with_chain_of_thought(question=samples)\n",
    "\n",
    "# Print the input, the chain of thought, and the prediction.\n",
    "print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Example({'label': '感激', 'text': '好的。知道了。谢谢您', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '没有,谢谢,再见', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '行。谢谢了', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '感激', 'text': '哦,我再试下,谢谢', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '太忙了,客服太少了吧', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '我这是无线流量怎样说欠费了', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '就是因为现在没办法归还,又不使用', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?', 'score': ' 0.8', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '我十四号回家老家过年了估计都还没有收到货', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '中性', 'text': '点错支付宝了。付不了款', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '太慢了,外面零下呢', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '可是客人着急啊', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '好的,请尽快邮寄。谢谢。', 'score': ' 0.9', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '已付款,请尽快处理,谢谢', 'score': ' 0.9', 'pred_label': '感激', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '你赶紧结束', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '你们这个急人', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '可是你们回款太慢了', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '焦急', 'text': '物流那么慢的吗?不是照片出关成功了吗?', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '早就还了,怎么扣那么多钱', 'score': ' 0.8', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '什么鬼', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '我的账号怎么不在了', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '够硬气', 'score': ' 0.8', 'pred_label': '生气', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '这个还扣我费用啊', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '不交诚意金聊不了嘛不交诚意金聊不了嘛', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '湖南能用???这个', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '就是坑坑洼洼的,你可能看到??', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '惊讶', 'text': '比抢火车票还厉害', 'score': ' 0.7', 'pred_label': '抱怨', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '亲爱的,上午好!', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '哈哈哈好吧', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '高兴', 'text': '哦,哈哈', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '抱怨', 'text': '你听的明白我说的话么', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n",
      "Question: Example({'label': '抱怨', 'text': '能看到我还在用跟你这么说', 'score': ' 0.5', 'pred_label': '中性', 'keywords': None}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "# 这样可以把答案和问题对应起来\n",
    "for sample, prediction in zip(sample_set, pred.answer.split(\"\\n\")):\n",
    "    sample[\"score\"] = prediction.split(\",\")[1]\n",
    "    sample[\"pred_label\"] = prediction.split(\",\")[0].split(\" \")[-1]\n",
    "    if sample[\"pred_label\"] != sample[\"label\"]:\n",
    "        print(f\"Question: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "sentiment analysis from text\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: list of input text\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "[1] «好的。知道了。谢谢您»\n",
      "[2] «非常感谢公司这么好的售后服务»\n",
      "[3] «谢谢你!不用了»\n",
      "[4] «哦哦,谢谢[emoji029]»\n",
      "[5] «嗯嗯,好的,太感谢了?»\n",
      "[6] «不用了!谢谢你啦»\n",
      "[7] «谢谢,我己经找到。麻烦你了亲»\n",
      "[8] «是这个,谢谢了»\n",
      "[9] «谢谢!没事儿。»\n",
      "[10] «没有,谢谢,再见»\n",
      "[11] «没有了。。非常感谢»\n",
      "[12] «行。谢谢了»\n",
      "[13] «嗯嗯,谢谢您»\n",
      "[14] «哦,我再试下,谢谢»\n",
      "[15] «之前我一直在同一机柜上扫码»\n",
      "[16] «太忙了,客服太少了吧»\n",
      "[17] «可是我的营业执照上有这个医疗器械的类目»\n",
      "[18] «说和商品同送的»\n",
      "[19] «我这是无线流量怎样说欠费了»\n",
      "[20] «您好,查询一下»\n",
      "[21] «你是真人还是电脑»\n",
      "[22] «我借充电宝才发现我的充电宝在菏泽»\n",
      "[23] «就是因为现在没办法归还,又不使用»\n",
      "[24] «虹桥火车站,国家会展中心附近»\n",
      "[25] «是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?»\n",
      "[26] «转债速度»\n",
      "[27] «我十四号回家老家过年了估计都还没有收到货»\n",
      "[28] «点错支付宝了。付不了款»\n",
      "[29] «太慢了,外面零下呢»\n",
      "[30] «可是客人着急啊»\n",
      "[31] «好的,请尽快邮寄。谢谢。»\n",
      "[32] «已付款,请尽快处理,谢谢»\n",
      "[33] «这个单子很紧急»\n",
      "[34] «你好我买的口红怎么还没发货呢?»\n",
      "[35] «你好,我的为什么那么久还没到嘞»\n",
      "[36] «麻烦您帮忙查一下,尽快安排发货,谢谢了»\n",
      "[37] «你赶紧结束»\n",
      "[38] «你们这个急人»\n",
      "[39] «可是你们回款太慢了»\n",
      "[40] «帮我催一催谢谢»\n",
      "[41] «我的期末成绩为什么还查不到»\n",
      "[42] «物流那么慢的吗?不是照片出关成功了吗?»\n",
      "[43] «吓死人啊»\n",
      "[44] «早就还了,怎么扣那么多钱»\n",
      "[45] «这是真的不回我了?»\n",
      "[46] «我看下都吓我一跳»\n",
      "[47] «什么鬼»\n",
      "[48] «我的账号怎么不在了»\n",
      "[49] «现在查的这么严了?»\n",
      "[50] «应该没事了吧,好吓人»\n",
      "[51] «够硬气»\n",
      "[52] «这个还扣我费用啊»\n",
      "[53] «不交诚意金聊不了嘛不交诚意金聊不了嘛»\n",
      "[54] «湖南能用???这个»\n",
      "[55] «就是坑坑洼洼的,你可能看到??»\n",
      "[56] «比抢火车票还厉害»\n",
      "[57] «亲爱的,上午好!»\n",
      "[58] «出来了哈哈哈哈»\n",
      "[59] «女子我喜欢你。»\n",
      "[60] «太期待了»\n",
      "[61] «好开心啊»\n",
      "[62] «很高兴与您的对话哦»\n",
      "[63] «[emoji033]哈哈»\n",
      "[64] «爱你爱你[emoji007]»\n",
      "[65] «哈哈哈[emoji030]»\n",
      "[66] «哈哈哈好吧»\n",
      "[67] «天猫还便宜好多!太棒了»\n",
      "[68] «[emoji047]真好»\n",
      "[69] «祝生日快乐!»\n",
      "[70] «哦,哈哈»\n",
      "[71] «就是看在小蜜红薯又小又细才买的,这次的那么大,还粗,蒸着吃不好吃唉»\n",
      "[72] «都两天了,还没更新完»\n",
      "[73] «就改个手机号,怎么这么难»\n",
      "[74] «进水很慢。»\n",
      "[75] «购买产品很难,开放时间好短»\n",
      "[76] «你听的明白我说的话么»\n",
      "[77] «能看到我还在用跟你这么说»\n",
      "[78] «丢到反馈都很久了»\n",
      "[79] «物流信息好慢呀»\n",
      "[80] «我认识的很多小伙伴都说因为太难»\n",
      "[81] «系统这两天为什么老掉线»\n",
      "[82] «要一个一个重新建,再重新关联,好繁琐哇»\n",
      "[83] «我自己用了就知道有问题啊»\n",
      "[84] «除了客服无人处理了?»\n",
      "[85] «客户快骂死我了。车商也骂»\n",
      "[86] «我他妈知道归还,但是没有还的地方你胖揍上哪还»\n",
      "[87] «为什么每次都是非要联系了客服才能到呢?不联系就死活不到?这是什么做法?»\n",
      "[88] «我当时就很生气»\n",
      "[89] «你们在哪里可以投诉呢!»\n",
      "[90] «你死全家»\n",
      "[91] «老板死了»\n",
      "[92] «你们这些狗»\n",
      "[93] «换你吗逼»\n",
      "[94] «良心不会痛吗?»\n",
      "[95] «骗钱也不是这样骗的吧»\n",
      "[96] «不然我还会向市场监管部门投诉»\n",
      "[97] «我炸你妈逼呀!»\n",
      "[98] «这不是骗钱呢»\n",
      "[99] «就是用的这个啊»\n",
      "[100] «已经好了,谢谢~»\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We will analyze each text individually based on the context and the tone of the language used, and then classify the sentiment accordingly. The sentiment classification includes ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']. We will also assign a score from 0 to 1.0 to represent the intensity of the sentiment.\n",
      "\n",
      "Answer:\n",
      "[1] 中性, 0.5\n",
      "[2] 感激, 0.9\n",
      "[3] 感激, 0.8\n",
      "[4] 感激, 0.7\n",
      "[5] 感激, 0.8\n",
      "[6] 感激, 0.8\n",
      "[7] 感激, 0.9\n",
      "[8] 感激, 0.9\n",
      "[9] 感激, 0.9\n",
      "[10] 中性, 0.5\n",
      "[11] 感激, 0.9\n",
      "[12] 中性, 0.5\n",
      "[13] 感激, 0.8\n",
      "[14] 中性, 0.5\n",
      "[15] 中性, 0.5\n",
      "[16] 抱怨, 0.8\n",
      "[17] 中性, 0.5\n",
      "[18] 中性, 0.5\n",
      "[19] 抱怨, 0.7\n",
      "[20] 中性, 0.5\n",
      "[21] 中性, 0.5\n",
      "[22] 中性, 0.5\n",
      "[23] 抱怨, 0.7\n",
      "[24] 中性, 0.5\n",
      "[25] 感激, 0.8\n",
      "[26] 中性, 0.5\n",
      "[27] 抱怨, 0.7\n",
      "[28] 抱怨, 0.7\n",
      "[29] 抱怨, 0.8\n",
      "[30] 抱怨, 0.8\n",
      "[31] 感激, 0.9\n",
      "[32] 感激, 0.9\n",
      "[33] 焦急, 0.9\n",
      "[34] 焦急, 0.8\n",
      "[35] 焦急, 0.8\n",
      "[36] 焦急, 0.9\n",
      "[37] 生气, 0.8\n",
      "[38] 生气, 0.8\n",
      "[39] 抱怨, 0.8\n",
      "[40] 焦急, 0.9\n",
      "[41] 焦急, 0.8\n",
      "[42] 抱怨, 0.7\n",
      "[43] 惊讶, 0.9\n",
      "[44] 抱怨, 0.8\n",
      "[45] 惊讶, 0.9\n",
      "[46] 惊讶, 0.9\n",
      "[47] 生气, 0.8\n",
      "[48] 生气, 0.8\n",
      "[49] 惊讶, 0.9\n",
      "[50] 惊讶, 0.9\n",
      "[51] 生气, 0.8\n",
      "[52] 抱怨, 0.7\n",
      "[53] 抱怨, 0.7\n",
      "[54] 中性, 0.5\n",
      "[55] 抱怨, 0.7\n",
      "[56] 抱怨, 0.7\n",
      "[57] 中性, 0.5\n",
      "[58] 高兴, 0.9\n",
      "[59] 高兴, 0.9\n",
      "[60] 高兴, 0.9\n",
      "[61] 高兴, 0.9\n",
      "[62] 高兴, 0.9\n",
      "[63] 高兴, 0.9\n",
      "[64] 高兴, 0.9\n",
      "[65] 高兴, 0.9\n",
      "[66] 中性, 0.5\n",
      "[67] 高兴, 0.9\n",
      "[68] 高兴, 0.9\n",
      "[69] 高兴, 0.9\n",
      "[70] 中性, 0.5\n",
      "[71] 抱怨, 0.7\n",
      "[72] 抱怨, 0.7\n",
      "[73] 抱怨, 0.7\n",
      "[74] 抱怨, 0.7\n",
      "[75] 抱怨, 0.7\n",
      "[76] 中性, 0.5\n",
      "[77] 中性, 0.5\n",
      "[78] 抱怨, 0.7\n",
      "[79] 抱怨, 0.7\n",
      "[80] 抱怨, 0.7\n",
      "[81] 抱怨, 0.7\n",
      "[82] 抱怨, 0.7\n",
      "[83] 抱怨, 0.7\n",
      "[84] 抱怨, 0.7\n",
      "[85] 生气, 0.8\n",
      "[86] 生气, 0.8\n",
      "[87] 生气, 0.8\n",
      "[88] 生气, 0.8\n",
      "[89] 生气, 0.8\n",
      "[90] 生气, 0.8\n",
      "[91] 生气, 0.8\n",
      "[92] 生气, 0.8\n",
      "[93] 生气, 0.8\n",
      "[94] 生气, 0.8\n",
      "[95] 生气, 0.8\n",
      "[96] 生气, 0.8\n",
      "[97] 生气, 0.8\n",
      "[98] 生气, 0.8\n",
      "[99] 中性, 0.5\n",
      "[100] 感激, 0.9\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nsentiment analysis from text\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: list of input text\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\\n\\n---\\n\\nQuestion:\\n[1] «好的。知道了。谢谢您»\\n[2] «非常感谢公司这么好的售后服务»\\n[3] «谢谢你!不用了»\\n[4] «哦哦,谢谢[emoji029]»\\n[5] «嗯嗯,好的,太感谢了?»\\n[6] «不用了!谢谢你啦»\\n[7] «谢谢,我己经找到。麻烦你了亲»\\n[8] «是这个,谢谢了»\\n[9] «谢谢!没事儿。»\\n[10] «没有,谢谢,再见»\\n[11] «没有了。。非常感谢»\\n[12] «行。谢谢了»\\n[13] «嗯嗯,谢谢您»\\n[14] «哦,我再试下,谢谢»\\n[15] «之前我一直在同一机柜上扫码»\\n[16] «太忙了,客服太少了吧»\\n[17] «可是我的营业执照上有这个医疗器械的类目»\\n[18] «说和商品同送的»\\n[19] «我这是无线流量怎样说欠费了»\\n[20] «您好,查询一下»\\n[21] «你是真人还是电脑»\\n[22] «我借充电宝才发现我的充电宝在菏泽»\\n[23] «就是因为现在没办法归还,又不使用»\\n[24] «虹桥火车站,国家会展中心附近»\\n[25] «是的,我收货地点写的是我的单位,因为我们可能要出去耍哈。好的,谢谢?»\\n[26] «转债速度»\\n[27] «我十四号回家老家过年了估计都还没有收到货»\\n[28] «点错支付宝了。付不了款»\\n[29] «太慢了,外面零下呢»\\n[30] «可是客人着急啊»\\n[31] «好的,请尽快邮寄。谢谢。»\\n[32] «已付款,请尽快处理,谢谢»\\n[33] «这个单子很紧急»\\n[34] «你好我买的口红怎么还没发货呢?»\\n[35] «你好,我的为什么那么久还没到嘞»\\n[36] «麻烦您帮忙查一下,尽快安排发货,谢谢了»\\n[37] «你赶紧结束»\\n[38] «你们这个急人»\\n[39] «可是你们回款太慢了»\\n[40] «帮我催一催谢谢»\\n[41] «我的期末成绩为什么还查不到»\\n[42] «物流那么慢的吗?不是照片出关成功了吗?»\\n[43] «吓死人啊»\\n[44] «早就还了,怎么扣那么多钱»\\n[45] «这是真的不回我了?»\\n[46] «我看下都吓我一跳»\\n[47] «什么鬼»\\n[48] «我的账号怎么不在了»\\n[49] «现在查的这么严了?»\\n[50] «应该没事了吧,好吓人»\\n[51] «够硬气»\\n[52] «这个还扣我费用啊»\\n[53] «不交诚意金聊不了嘛不交诚意金聊不了嘛»\\n[54] «湖南能用???这个»\\n[55] «就是坑坑洼洼的,你可能看到??»\\n[56] «比抢火车票还厉害»\\n[57] «亲爱的,上午好!»\\n[58] «出来了哈哈哈哈»\\n[59] «女子我喜欢你。»\\n[60] «太期待了»\\n[61] «好开心啊»\\n[62] «很高兴与您的对话哦»\\n[63] «[emoji033]哈哈»\\n[64] «爱你爱你[emoji007]»\\n[65] «哈哈哈[emoji030]»\\n[66] «哈哈哈好吧»\\n[67] «天猫还便宜好多!太棒了»\\n[68] «[emoji047]真好»\\n[69] «祝生日快乐!»\\n[70] «哦,哈哈»\\n[71] «就是看在小蜜红薯又小又细才买的,这次的那么大,还粗,蒸着吃不好吃唉»\\n[72] «都两天了,还没更新完»\\n[73] «就改个手机号,怎么这么难»\\n[74] «进水很慢。»\\n[75] «购买产品很难,开放时间好短»\\n[76] «你听的明白我说的话么»\\n[77] «能看到我还在用跟你这么说»\\n[78] «丢到反馈都很久了»\\n[79] «物流信息好慢呀»\\n[80] «我认识的很多小伙伴都说因为太难»\\n[81] «系统这两天为什么老掉线»\\n[82] «要一个一个重新建,再重新关联,好繁琐哇»\\n[83] «我自己用了就知道有问题啊»\\n[84] «除了客服无人处理了?»\\n[85] «客户快骂死我了。车商也骂»\\n[86] «我他妈知道归还,但是没有还的地方你胖揍上哪还»\\n[87] «为什么每次都是非要联系了客服才能到呢?不联系就死活不到?这是什么做法?»\\n[88] «我当时就很生气»\\n[89] «你们在哪里可以投诉呢!»\\n[90] «你死全家»\\n[91] «老板死了»\\n[92] «你们这些狗»\\n[93] «换你吗逼»\\n[94] «良心不会痛吗?»\\n[95] «骗钱也不是这样骗的吧»\\n[96] «不然我还会向市场监管部门投诉»\\n[97] «我炸你妈逼呀!»\\n[98] «这不是骗钱呢»\\n[99] «就是用的这个啊»\\n[100] «已经好了,谢谢~»\\nReasoning: Let's think step by step in order to\\x1b[32m produce the answer. We will analyze each text individually based on the context and the tone of the language used, and then classify the sentiment accordingly. The sentiment classification includes ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']. We will also assign a score from 0 to 1.0 to represent the intensity of the sentiment.\\n\\nAnswer:\\n[1] 中性, 0.5\\n[2] 感激, 0.9\\n[3] 感激, 0.8\\n[4] 感激, 0.7\\n[5] 感激, 0.8\\n[6] 感激, 0.8\\n[7] 感激, 0.9\\n[8] 感激, 0.9\\n[9] 感激, 0.9\\n[10] 中性, 0.5\\n[11] 感激, 0.9\\n[12] 中性, 0.5\\n[13] 感激, 0.8\\n[14] 中性, 0.5\\n[15] 中性, 0.5\\n[16] 抱怨, 0.8\\n[17] 中性, 0.5\\n[18] 中性, 0.5\\n[19] 抱怨, 0.7\\n[20] 中性, 0.5\\n[21] 中性, 0.5\\n[22] 中性, 0.5\\n[23] 抱怨, 0.7\\n[24] 中性, 0.5\\n[25] 感激, 0.8\\n[26] 中性, 0.5\\n[27] 抱怨, 0.7\\n[28] 抱怨, 0.7\\n[29] 抱怨, 0.8\\n[30] 抱怨, 0.8\\n[31] 感激, 0.9\\n[32] 感激, 0.9\\n[33] 焦急, 0.9\\n[34] 焦急, 0.8\\n[35] 焦急, 0.8\\n[36] 焦急, 0.9\\n[37] 生气, 0.8\\n[38] 生气, 0.8\\n[39] 抱怨, 0.8\\n[40] 焦急, 0.9\\n[41] 焦急, 0.8\\n[42] 抱怨, 0.7\\n[43] 惊讶, 0.9\\n[44] 抱怨, 0.8\\n[45] 惊讶, 0.9\\n[46] 惊讶, 0.9\\n[47] 生气, 0.8\\n[48] 生气, 0.8\\n[49] 惊讶, 0.9\\n[50] 惊讶, 0.9\\n[51] 生气, 0.8\\n[52] 抱怨, 0.7\\n[53] 抱怨, 0.7\\n[54] 中性, 0.5\\n[55] 抱怨, 0.7\\n[56] 抱怨, 0.7\\n[57] 中性, 0.5\\n[58] 高兴, 0.9\\n[59] 高兴, 0.9\\n[60] 高兴, 0.9\\n[61] 高兴, 0.9\\n[62] 高兴, 0.9\\n[63] 高兴, 0.9\\n[64] 高兴, 0.9\\n[65] 高兴, 0.9\\n[66] 中性, 0.5\\n[67] 高兴, 0.9\\n[68] 高兴, 0.9\\n[69] 高兴, 0.9\\n[70] 中性, 0.5\\n[71] 抱怨, 0.7\\n[72] 抱怨, 0.7\\n[73] 抱怨, 0.7\\n[74] 抱怨, 0.7\\n[75] 抱怨, 0.7\\n[76] 中性, 0.5\\n[77] 中性, 0.5\\n[78] 抱怨, 0.7\\n[79] 抱怨, 0.7\\n[80] 抱怨, 0.7\\n[81] 抱怨, 0.7\\n[82] 抱怨, 0.7\\n[83] 抱怨, 0.7\\n[84] 抱怨, 0.7\\n[85] 生气, 0.8\\n[86] 生气, 0.8\\n[87] 生气, 0.8\\n[88] 生气, 0.8\\n[89] 生气, 0.8\\n[90] 生气, 0.8\\n[91] 生气, 0.8\\n[92] 生气, 0.8\\n[93] 生气, 0.8\\n[94] 生气, 0.8\\n[95] 生气, 0.8\\n[96] 生气, 0.8\\n[97] 生气, 0.8\\n[98] 生气, 0.8\\n[99] 中性, 0.5\\n[100] 感激, 0.9\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BootstrapFewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:18<00:33,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "import dspy\n",
    "from dsp import passages2text\n",
    "\n",
    "\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"sentiment analysis from text\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"list of input text\", format=passages2text)\n",
    "    answer = dspy.OutputField(\n",
    "        desc=\"question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\",\n",
    "        type=list,\n",
    "    )\n",
    "\n",
    "\n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(BasicQA)\n",
    "\n",
    "    # 这里的 forward 会被调用 Sample 的 inputs_keys 作为参数,\n",
    "    # 比如那里的 text 在这里，需要作为参数传给 forward(text = sample.get(\"text\"))\n",
    "    def forward(self, text=None):\n",
    "        return self.prog(question=text)\n",
    "\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    update_sample([example], pred.answer)\n",
    "    return example[\"label\"] == example[\"pred_label\"]\n",
    "\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_cot = teleprompter.compile(CoT(), trainset=train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': '系统检测到输入或生成内容可能包含不安全或敏感内容，请您避免输入易产生敏感内容的提示语，感谢您的配合。 (request id: 2024071819313738640109360580156)', 'type': '', 'param': '', 'code': '1301'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(samples)\n\u001b[0;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_cot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/primitives/program.py:26\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[147], line 23\u001b[0m, in \u001b[0;36mCoT.forward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/primitives/program.py:26\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/predict/chain_of_thought.py:37\u001b[0m, in \u001b[0;36mChainOfThought.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     36\u001b[0m signature \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict\u001b[38;5;241m.\u001b[39mextended_signature \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/predict/predict.py:78\u001b[0m, in \u001b[0;36mPredict.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/predict/predict.py:116\u001b[0m, in \u001b[0;36mPredict.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     completions \u001b[38;5;241m=\u001b[39m new_generate(lm, signature, dsp\u001b[38;5;241m.\u001b[39mExample(demos\u001b[38;5;241m=\u001b[39mdemos, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[43mold_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m pred \u001b[38;5;241m=\u001b[39m Prediction\u001b[38;5;241m.\u001b[39mfrom_completions(completions, signature\u001b[38;5;241m=\u001b[39msignature)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mtrace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/predict/predict.py:143\u001b[0m, in \u001b[0;36mold_generate\u001b[0;34m(demos, signature, kwargs, config, lm, stage)\u001b[0m\n\u001b[1;32m    140\u001b[0m template \u001b[38;5;241m=\u001b[39m signature_to_template(signature)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     x, C \u001b[38;5;241m=\u001b[39m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Note: query_only=True means the instructions and examples are not included.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mcontext(lm\u001b[38;5;241m=\u001b[39mlm, query_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/primitives/predict.py:73\u001b[0m, in \u001b[0;36m_generate.<locals>.do_generate\u001b[0;34m(example, stage, max_depth, original_example)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Generate and extract the fields.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m prompt \u001b[38;5;241m=\u001b[39m template(example)\n\u001b[0;32m---> 73\u001b[0m completions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m completions: \u001b[38;5;28mlist\u001b[39m[Example] \u001b[38;5;241m=\u001b[39m [template\u001b[38;5;241m.\u001b[39mextract(example, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m completions]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Find the completions that are most complete.\u001b[39;00m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:178\u001b[0m, in \u001b[0;36mGPT3.__call__\u001b[0;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m return_sorted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor now\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# if kwargs.get(\"n\", 1) > 1:\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m#     if self.model_type == \"chat\":\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#         kwargs = {**kwargs}\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#         kwargs = {**kwargs, \"logprobs\": 5}\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_usage(response)\n\u001b[1;32m    181\u001b[0m choices \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[38;5;241m=\u001b[39m (tries \u001b[38;5;241m==\u001b[39m max_tries_value)\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:144\u001b[0m, in \u001b[0;36mGPT3.request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:117\u001b[0m, in \u001b[0;36mGPT3.basic_request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m messages\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstringify_request\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(kwargs)}\n\u001b[0;32m--> 117\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m prompt\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:269\u001b[0m, in \u001b[0;36mchat_request\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m OPENAI_LEGACY:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cached_gpt3_turbo_request_v2_wrapped(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/cache_utils.py:16\u001b[0m, in \u001b[0;36mnoop_decorator.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:262\u001b[0m, in \u001b[0;36mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m cache_turn_on \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;129m@NotebookCacheMemory\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1_cached_gpt3_turbo_request_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/joblib/memory.py:655\u001b[0m, in \u001b[0;36mMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/joblib/memory.py:598\u001b[0m, in \u001b[0;36mMemorizedFunc._cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    595\u001b[0m     must_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m must_call:\n\u001b[0;32m--> 598\u001b[0m     out, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmmap_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;66;03m# Memmap the output at the first call to be consistent with\u001b[39;00m\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;66;03m# later calls\u001b[39;00m\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/joblib/memory.py:856\u001b[0m, in \u001b[0;36mMemorizedFunc.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28mprint\u001b[39m(format_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, args, kwargs))\n\u001b[0;32m--> 856\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_backend\u001b[38;5;241m.\u001b[39mdump_item(\n\u001b[1;32m    858\u001b[0m     [func_id, args_id], output, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose)\n\u001b[1;32m    860\u001b[0m duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dsp/modules/gpt3.py:256\u001b[0m, in \u001b[0;36mv1_cached_gpt3_turbo_request_v2\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstringify_request\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    255\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstringify_request\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1054\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': '系统检测到输入或生成内容可能包含不安全或敏感内容，请您避免输入易产生敏感内容的提示语，感谢您的配合。 (request id: 2024071819313738640109360580156)', 'type': '', 'param': '', 'code': '1301'}}"
     ]
    }
   ],
   "source": [
    "text = \"\\n\".join(samples)\n",
    "pred = compiled_cot(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BadRequestError: Error code: 400 - {'error': {'message': '系统检测到输入或生成内容可能包含不安全或敏感内容，请您避免输入易产生敏感内容的提示语，感谢您的配合。 (request id: 2024071819313738640109360580156)', 'type': '', 'param': '', 'code': '1301'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "sentiment analysis from text\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: list of input text\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 ['中性', '惊讶', '感激', '抱怨', '焦急', '生气', '高兴']\n",
      "\n",
      "---\n",
      "\n",
      "Question: 我看下都吓我一跳\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We need to analyze the sentiment of the given text. The text \"我看下都吓我一跳\" can be broken down as follows:\n",
      "\n",
      "1. \"我看下\" - This part of the sentence indicates a sudden realization or discovery, which could be neutral or slightly surprising.\n",
      "2. \"都吓我一跳\" - This phrase explicitly conveys a sense of surprise or shock.\n",
      "\n",
      "Considering these elements, the sentiment of the text is likely to be '惊讶' (surprise).\n",
      "\n",
      "Answer: 惊讶,0.8\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nsentiment analysis from text\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: list of input text\\nReasoning: Let\\'s think step by step in order to ${produce the answer}. We ...\\nAnswer: question 中每一个输入`text`的情绪分类和评分(0-1.0),格式如 惊讶,0.7 抱怨,0.9 情绪分类包括 [\\'中性\\', \\'惊讶\\', \\'感激\\', \\'抱怨\\', \\'焦急\\', \\'生气\\', \\'高兴\\']\\n\\n---\\n\\nQuestion: 我看下都吓我一跳\\nReasoning: Let\\'s think step by step in order to\\x1b[32m produce the answer. We need to analyze the sentiment of the given text. The text \"我看下都吓我一跳\" can be broken down as follows:\\n\\n1. \"我看下\" - This part of the sentence indicates a sudden realization or discovery, which could be neutral or slightly surprising.\\n2. \"都吓我一跳\" - This phrase explicitly conveys a sense of surprise or shock.\\n\\nConsidering these elements, the sentiment of the text is likely to be \\'惊讶\\' (surprise).\\n\\nAnswer: 惊讶,0.8\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_sample(sample_set, pred.answer)\n",
    "print(sample_error_rate(sample_set))\n",
    "\n",
    "for sample in sample_set:\n",
    "    if sample[\"pred_label\"] != sample[\"label\"]:\n",
    "        print(f\"Question: {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]WARNING: Not all input fields were provided to module. Present: []. Missing: ['question'].\n",
      "  0%|          | 0/50 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:dspy.evaluate.evaluate:\u001b[2m2024-07-18T06:01:47.769639Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t 'Example' object has no attribute 'answer'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):   2%|▏         | 1/50 [00:03<02:29,  3.05s/it]WARNING: Not all input fields were provided to module. Present: []. Missing: ['question'].\n",
      "Average Metric: 0.0 / 1  (0.0):   2%|▏         | 1/50 [00:03<02:29,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:dspy.evaluate.evaluate:\u001b[2m2024-07-18T06:01:47.775280Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t 'Example' object has no attribute 'answer'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):   2%|▏         | 1/50 [00:03<02:29,  3.05s/it]WARNING: Not all input fields were provided to module. Present: []. Missing: ['question'].\n",
      "Average Metric: 0.0 / 2  (0.0):   4%|▍         | 2/50 [00:03<02:26,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:dspy.evaluate.evaluate:\u001b[2m2024-07-18T06:01:47.777839Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t 'Example' object has no attribute 'answer'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):   4%|▍         | 2/50 [00:03<02:26,  3.05s/it]WARNING: Not all input fields were provided to module. Present: []. Missing: ['question'].\n",
      "Average Metric: 0.0 / 3  (0.0):   6%|▌         | 3/50 [00:03<02:23,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:dspy.evaluate.evaluate:\u001b[2m2024-07-18T06:01:47.781370Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t 'Example' object has no attribute 'answer'\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):   6%|▌         | 3/50 [00:03<02:23,  3.05s/it]WARNING: Not all input fields were provided to module. Present: []. Missing: ['question'].\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m metric \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mevaluate\u001b[38;5;241m.\u001b[39manswer_exact_match\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluate_on_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:191\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mtqdm\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_single_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_multi_thread(\n\u001b[1;32m    194\u001b[0m         wrapped_program,\n\u001b[1;32m    195\u001b[0m         devset,\n\u001b[1;32m    196\u001b[0m         num_threads,\n\u001b[1;32m    197\u001b[0m         display_progress,\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:67\u001b[0m, in \u001b[0;36mEvaluate._execute_single_thread\u001b[0;34m(self, wrapped_program, devset, display_progress)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, arg \u001b[38;5;129;01min\u001b[39;00m devset:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging_redirect_tqdm():\n\u001b[0;32m---> 67\u001b[0m         example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m         reordered_devset\u001b[38;5;241m.\u001b[39mappend((example_idx, example, prediction, score))\n\u001b[1;32m     69\u001b[0m         ncorrect \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:178\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    176\u001b[0m     current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    180\u001b[0m dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for example in dev set: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m example_idx, example, {}, \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:161\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m program(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample\u001b[38;5;241m.\u001b[39minputs())\n\u001b[0;32m--> 161\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# increment assert and suggest failures to program's attributes\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_assert_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/evaluate/metrics.py:7\u001b[0m, in \u001b[0;36manswer_exact_match\u001b[0;34m(example, pred, trace, frac)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manswer_exact_match\u001b[39m(example, pred, trace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manswer\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(example\u001b[38;5;241m.\u001b[39manswer) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(example\u001b[38;5;241m.\u001b[39manswer) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39manswer_match(pred\u001b[38;5;241m.\u001b[39manswer, [example\u001b[38;5;241m.\u001b[39manswer], frac\u001b[38;5;241m=\u001b[39mfrac)\n",
      "File \u001b[0;32m~/.py/venvs/qa/lib/python3.11/site-packages/dspy/primitives/example.py:24\u001b[0m, in \u001b[0;36mExample.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store[key]\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'answer'"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_base = Evaluate(\n",
    "    devset=test_dataset, num_threads=1, display_progress=True, display_table=5\n",
    ")\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate_on_base(generate_answer, metric=metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
